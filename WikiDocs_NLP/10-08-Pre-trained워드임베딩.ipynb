{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3f53c4e",
   "metadata": {},
   "source": [
    "# 10. 워드 임베딩(Word Embedding)\n",
    "\n",
    "## 08) 사전 훈련된 워드 임베딩(Pre-trained Word Embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7e31b2",
   "metadata": {},
   "source": [
    "### 1. 케라스 임베딩 층(Keras Embedding layer)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "297e1a20",
   "metadata": {},
   "source": [
    "#### 1) 임베딩 층은 룩업 테이블이다.\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fc8a8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "sentences = ['nice great best amazing', 'stop lies', 'pitiful nerd', 'excellent work', 'supreme quality', 'bad', 'highly respectable']\n",
    "y_train = [1, 0, 0, 1, 1, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0d4cccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합 : 16\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "vocab_size = len(tokenizer.word_index) + 1 # 패딩을 고려하여 +1\n",
    "print('단어 집합 :',vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41932376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 결과 : [[1, 2, 3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13], [14, 15]]\n"
     ]
    }
   ],
   "source": [
    "X_encoded = tokenizer.texts_to_sequences(sentences)\n",
    "print('정수 인코딩 결과 :',X_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "911dc087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대 길이 : 4\n"
     ]
    }
   ],
   "source": [
    "max_len = max(len(l) for l in X_encoded)\n",
    "print('최대 길이 :',max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90e5bed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "패딩 결과 :\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  0  0]\n",
      " [ 7  8  0  0]\n",
      " [ 9 10  0  0]\n",
      " [11 12  0  0]\n",
      " [13  0  0  0]\n",
      " [14 15  0  0]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train = pad_sequences(X_encoded, maxlen=max_len, padding='post')\n",
    "y_train = np.array(y_train)\n",
    "print('패딩 결과 :')\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1695756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 - 1s - loss: 0.6958 - acc: 0.5714\n",
      "Epoch 2/100\n",
      "1/1 - 0s - loss: 0.6943 - acc: 0.5714\n",
      "Epoch 3/100\n",
      "1/1 - 0s - loss: 0.6929 - acc: 0.5714\n",
      "Epoch 4/100\n",
      "1/1 - 0s - loss: 0.6914 - acc: 0.5714\n",
      "Epoch 5/100\n",
      "1/1 - 0s - loss: 0.6900 - acc: 0.5714\n",
      "Epoch 6/100\n",
      "1/1 - 0s - loss: 0.6886 - acc: 0.7143\n",
      "Epoch 7/100\n",
      "1/1 - 0s - loss: 0.6871 - acc: 0.7143\n",
      "Epoch 8/100\n",
      "1/1 - 0s - loss: 0.6857 - acc: 0.7143\n",
      "Epoch 9/100\n",
      "1/1 - 0s - loss: 0.6843 - acc: 0.7143\n",
      "Epoch 10/100\n",
      "1/1 - 0s - loss: 0.6829 - acc: 0.8571\n",
      "Epoch 11/100\n",
      "1/1 - 0s - loss: 0.6815 - acc: 0.8571\n",
      "Epoch 12/100\n",
      "1/1 - 0s - loss: 0.6801 - acc: 0.8571\n",
      "Epoch 13/100\n",
      "1/1 - 0s - loss: 0.6787 - acc: 0.8571\n",
      "Epoch 14/100\n",
      "1/1 - 0s - loss: 0.6773 - acc: 1.0000\n",
      "Epoch 15/100\n",
      "1/1 - 0s - loss: 0.6759 - acc: 0.8571\n",
      "Epoch 16/100\n",
      "1/1 - 0s - loss: 0.6745 - acc: 0.8571\n",
      "Epoch 17/100\n",
      "1/1 - 0s - loss: 0.6730 - acc: 0.8571\n",
      "Epoch 18/100\n",
      "1/1 - 0s - loss: 0.6716 - acc: 0.8571\n",
      "Epoch 19/100\n",
      "1/1 - 0s - loss: 0.6702 - acc: 0.8571\n",
      "Epoch 20/100\n",
      "1/1 - 0s - loss: 0.6688 - acc: 0.8571\n",
      "Epoch 21/100\n",
      "1/1 - 0s - loss: 0.6674 - acc: 0.8571\n",
      "Epoch 22/100\n",
      "1/1 - 0s - loss: 0.6660 - acc: 0.8571\n",
      "Epoch 23/100\n",
      "1/1 - 0s - loss: 0.6645 - acc: 0.8571\n",
      "Epoch 24/100\n",
      "1/1 - 0s - loss: 0.6631 - acc: 0.8571\n",
      "Epoch 25/100\n",
      "1/1 - 0s - loss: 0.6617 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "1/1 - 0s - loss: 0.6602 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 - 0s - loss: 0.6587 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 - 0s - loss: 0.6573 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 - 0s - loss: 0.6558 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 - 0s - loss: 0.6543 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 - 0s - loss: 0.6529 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 - 0s - loss: 0.6514 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 - 0s - loss: 0.6499 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 - 0s - loss: 0.6484 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 - 0s - loss: 0.6468 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 - 0s - loss: 0.6453 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 - 0s - loss: 0.6438 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 - 0s - loss: 0.6422 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 - 0s - loss: 0.6407 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 - 0s - loss: 0.6391 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 - 0s - loss: 0.6375 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 - 0s - loss: 0.6360 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 - 0s - loss: 0.6344 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 - 0s - loss: 0.6328 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 - 0s - loss: 0.6312 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 - 0s - loss: 0.6295 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 - 0s - loss: 0.6279 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 - 0s - loss: 0.6263 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 - 0s - loss: 0.6246 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 - 0s - loss: 0.6230 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 - 0s - loss: 0.6213 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 - 0s - loss: 0.6196 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 - 0s - loss: 0.6179 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 - 0s - loss: 0.6163 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 - 0s - loss: 0.6146 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 - 0s - loss: 0.6128 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 - 0s - loss: 0.6111 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 - 0s - loss: 0.6094 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 - 0s - loss: 0.6077 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 - 0s - loss: 0.6059 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 - 0s - loss: 0.6041 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 - 0s - loss: 0.6024 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 - 0s - loss: 0.6006 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 - 0s - loss: 0.5988 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 - 0s - loss: 0.5970 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 - 0s - loss: 0.5952 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 - 0s - loss: 0.5934 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 - 0s - loss: 0.5916 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 - 0s - loss: 0.5898 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 - 0s - loss: 0.5879 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 - 0s - loss: 0.5861 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 - 0s - loss: 0.5843 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 - 0s - loss: 0.5824 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 - 0s - loss: 0.5805 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 - 0s - loss: 0.5787 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 - 0s - loss: 0.5768 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 - 0s - loss: 0.5749 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 - 0s - loss: 0.5730 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 - 0s - loss: 0.5711 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 - 0s - loss: 0.5692 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 - 0s - loss: 0.5672 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 - 0s - loss: 0.5653 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 - 0s - loss: 0.5634 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 - 0s - loss: 0.5614 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 - 0s - loss: 0.5595 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 - 0s - loss: 0.5575 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 - 0s - loss: 0.5556 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 - 0s - loss: 0.5536 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 - 0s - loss: 0.5516 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 - 0s - loss: 0.5497 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 - 0s - loss: 0.5477 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 - 0s - loss: 0.5457 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 - 0s - loss: 0.5437 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 - 0s - loss: 0.5417 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 - 0s - loss: 0.5397 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 - 0s - loss: 0.5377 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 - 0s - loss: 0.5356 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 - 0s - loss: 0.5336 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 - 0s - loss: 0.5316 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 - 0s - loss: 0.5295 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22bec7f3198>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
    "\n",
    "embedding_dim = 4\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.fit(X_train, y_train, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf1e9c2",
   "metadata": {},
   "source": [
    "### 2. 사전 훈련된 워드 임베딩(Pre-Trained Word Embedding) 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604791de",
   "metadata": {},
   "source": [
    "#### 1) 사전 훈련된 GloVe 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "007f9afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve, urlopen\n",
    "import gzip\n",
    "import zipfile\n",
    "\n",
    "# urlretrieve(\"http://nlp.stanford.edu/data/glove.6B.zip\", \n",
    "#             filename=\"preTrained/glove.6B.zip\")\n",
    "# zf = zipfile.ZipFile('preTrained/glove.6B.zip')\n",
    "# zf.extractall() \n",
    "# zf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa426555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000개의 Embedding vector가 있습니다.\n"
     ]
    }
   ],
   "source": [
    "embedding_dict = dict()\n",
    "\n",
    "f = open('preTrained/glove.6B.100d.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in f:\n",
    "    word_vector = line.split()\n",
    "    word = word_vector[0]\n",
    "\n",
    "    # 100개의 값을 가지는 array로 변환\n",
    "    word_vector_arr = np.asarray(word_vector[1:], dtype='float32')\n",
    "    embedding_dict[word] = word_vector_arr\n",
    "f.close()\n",
    "\n",
    "print('%s개의 Embedding vector가 있습니다.' % len(embedding_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9300b21d",
   "metadata": {},
   "source": [
    "임의의 단어 'respectable'의 임베딩 벡터값과 크기를 출력해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d211385",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.049773   0.19903    0.10585    0.1391    -0.32395    0.44053\n",
      "  0.3947    -0.22805   -0.25793    0.49768    0.15384   -0.08831\n",
      "  0.0782    -0.8299    -0.037788   0.16772   -0.45197   -0.17085\n",
      "  0.74756    0.98256    0.81872    0.28507    0.16178   -0.48626\n",
      " -0.006265  -0.92469   -0.30625   -0.067318  -0.046762  -0.76291\n",
      " -0.0025264 -0.018795   0.12882   -0.52457    0.3586     0.43119\n",
      " -0.89477   -0.057421  -0.53724    0.25587    0.55195    0.44698\n",
      " -0.24252    0.29946    0.25776   -0.8717     0.68426   -0.05688\n",
      " -0.1848    -0.59352   -0.11227   -0.57692   -0.013593   0.18488\n",
      " -0.32507   -0.90171    0.17672    0.075601   0.54896   -0.21488\n",
      " -0.54018   -0.45882   -0.79536    0.26331    0.18879   -0.16363\n",
      "  0.3975     0.1099     0.1164    -0.083499   0.50159    0.35802\n",
      "  0.25677    0.088546   0.42108    0.28674   -0.71285   -0.82915\n",
      "  0.15297   -0.82712    0.022112   1.067     -0.31776    0.1211\n",
      " -0.069755  -0.61327    0.27308   -0.42638   -0.085084  -0.17694\n",
      " -0.0090944  0.1109     0.62543   -0.23682   -0.44928   -0.3667\n",
      " -0.21616   -0.19187   -0.032502   0.38025  ]\n",
      "벡터의 차원 수 : 100\n"
     ]
    }
   ],
   "source": [
    "print(embedding_dict['respectable'])\n",
    "print('벡터의 차원 수 :',len(embedding_dict['respectable']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be11d776",
   "metadata": {},
   "source": [
    "모든 값이 0으로 채워진 임베딩 행렬을 만들어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3605b300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 행렬의 크기(shape) : (16, 100)\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "print('임베딩 행렬의 크기(shape) :', np.shape(embedding_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479839fd",
   "metadata": {},
   "source": [
    "기존 데이터의 각 단어와 맵핑된 정수값을 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4bf4b76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('nice', 1), ('great', 2), ('best', 3), ('amazing', 4), ('stop', 5), ('lies', 6), ('pitiful', 7), ('nerd', 8), ('excellent', 9), ('work', 10), ('supreme', 11), ('quality', 12), ('bad', 13), ('highly', 14), ('respectable', 15)])\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11342888",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, index in tokenizer.word_index.items():\n",
    "    # 단어와 맵핑되는 사전 훈련된 임베딩 벡터값\n",
    "    vector_value = embedding_dict.get(word)\n",
    "    if vector_value is not None:\n",
    "        embedding_matrix[index] = vector_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89def818",
   "metadata": {},
   "source": [
    "Embedding layer에 embedding_matrix를 초기값으로 설정합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49afce2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 - 0s - loss: 0.6752 - acc: 0.7143\n",
      "Epoch 2/100\n",
      "1/1 - 0s - loss: 0.6535 - acc: 0.7143\n",
      "Epoch 3/100\n",
      "1/1 - 0s - loss: 0.6325 - acc: 0.7143\n",
      "Epoch 4/100\n",
      "1/1 - 0s - loss: 0.6125 - acc: 0.7143\n",
      "Epoch 5/100\n",
      "1/1 - 0s - loss: 0.5933 - acc: 0.7143\n",
      "Epoch 6/100\n",
      "1/1 - 0s - loss: 0.5749 - acc: 0.8571\n",
      "Epoch 7/100\n",
      "1/1 - 0s - loss: 0.5573 - acc: 0.8571\n",
      "Epoch 8/100\n",
      "1/1 - 0s - loss: 0.5406 - acc: 0.8571\n",
      "Epoch 9/100\n",
      "1/1 - 0s - loss: 0.5246 - acc: 0.8571\n",
      "Epoch 10/100\n",
      "1/1 - 0s - loss: 0.5093 - acc: 0.8571\n",
      "Epoch 11/100\n",
      "1/1 - 0s - loss: 0.4947 - acc: 0.8571\n",
      "Epoch 12/100\n",
      "1/1 - 0s - loss: 0.4808 - acc: 0.8571\n",
      "Epoch 13/100\n",
      "1/1 - 0s - loss: 0.4674 - acc: 0.8571\n",
      "Epoch 14/100\n",
      "1/1 - 0s - loss: 0.4545 - acc: 0.8571\n",
      "Epoch 15/100\n",
      "1/1 - 0s - loss: 0.4422 - acc: 0.8571\n",
      "Epoch 16/100\n",
      "1/1 - 0s - loss: 0.4304 - acc: 0.8571\n",
      "Epoch 17/100\n",
      "1/1 - 0s - loss: 0.4189 - acc: 0.8571\n",
      "Epoch 18/100\n",
      "1/1 - 0s - loss: 0.4080 - acc: 0.8571\n",
      "Epoch 19/100\n",
      "1/1 - 0s - loss: 0.3974 - acc: 0.8571\n",
      "Epoch 20/100\n",
      "1/1 - 0s - loss: 0.3871 - acc: 0.8571\n",
      "Epoch 21/100\n",
      "1/1 - 0s - loss: 0.3772 - acc: 0.8571\n",
      "Epoch 22/100\n",
      "1/1 - 0s - loss: 0.3677 - acc: 1.0000\n",
      "Epoch 23/100\n",
      "1/1 - 0s - loss: 0.3584 - acc: 1.0000\n",
      "Epoch 24/100\n",
      "1/1 - 0s - loss: 0.3495 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "1/1 - 0s - loss: 0.3408 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "1/1 - 0s - loss: 0.3324 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 - 0s - loss: 0.3243 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 - 0s - loss: 0.3165 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 - 0s - loss: 0.3089 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 - 0s - loss: 0.3015 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 - 0s - loss: 0.2944 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 - 0s - loss: 0.2875 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 - 0s - loss: 0.2808 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 - 0s - loss: 0.2743 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 - 0s - loss: 0.2680 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 - 0s - loss: 0.2620 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 - 0s - loss: 0.2561 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 - 0s - loss: 0.2504 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 - 0s - loss: 0.2449 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 - 0s - loss: 0.2395 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 - 0s - loss: 0.2343 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 - 0s - loss: 0.2293 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 - 0s - loss: 0.2245 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 - 0s - loss: 0.2198 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 - 0s - loss: 0.2152 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 - 0s - loss: 0.2108 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 - 0s - loss: 0.2065 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 - 0s - loss: 0.2024 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 - 0s - loss: 0.1983 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 - 0s - loss: 0.1944 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 - 0s - loss: 0.1906 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 - 0s - loss: 0.1870 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 - 0s - loss: 0.1834 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 - 0s - loss: 0.1799 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 - 0s - loss: 0.1766 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 - 0s - loss: 0.1733 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 - 0s - loss: 0.1701 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 - 0s - loss: 0.1670 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 - 0s - loss: 0.1640 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 - 0s - loss: 0.1611 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 - 0s - loss: 0.1583 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 - 0s - loss: 0.1555 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 - 0s - loss: 0.1528 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 - 0s - loss: 0.1502 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 - 0s - loss: 0.1477 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 - 0s - loss: 0.1452 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 - 0s - loss: 0.1428 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 - 0s - loss: 0.1404 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 - 0s - loss: 0.1382 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 - 0s - loss: 0.1359 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 - 0s - loss: 0.1338 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 - 0s - loss: 0.1316 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 - 0s - loss: 0.1296 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 - 0s - loss: 0.1276 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 - 0s - loss: 0.1256 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 - 0s - loss: 0.1237 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 - 0s - loss: 0.1218 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 - 0s - loss: 0.1200 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 - 0s - loss: 0.1182 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 - 0s - loss: 0.1165 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 - 0s - loss: 0.1148 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 - 0s - loss: 0.1131 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 - 0s - loss: 0.1115 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 - 0s - loss: 0.1099 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 - 0s - loss: 0.1084 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 - 0s - loss: 0.1068 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 - 0s - loss: 0.1054 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 - 0s - loss: 0.1039 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 - 0s - loss: 0.1025 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 - 0s - loss: 0.1011 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 - 0s - loss: 0.0998 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 - 0s - loss: 0.0985 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 - 0s - loss: 0.0972 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 - 0s - loss: 0.0959 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 - 0s - loss: 0.0947 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 - 0s - loss: 0.0934 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 - 0s - loss: 0.0922 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 - 0s - loss: 0.0911 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 - 0s - loss: 0.0899 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 - 0s - loss: 0.0888 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22d064fc630>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
    "\n",
    "output_dim = 100\n",
    "\n",
    "model = Sequential()\n",
    "e = Embedding(vocab_size, output_dim, weights=[embedding_matrix], input_length=max_len, trainable=False)\n",
    "model.add(e)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.fit(X_train, y_train, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512d134d",
   "metadata": {},
   "source": [
    "### 2) 사전 훈련된 Word2Vec 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3839d9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델의 크기(shape) : (3000000, 300)\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "# urlretrieve(\"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\", \\\n",
    "#             filename=\"preTrained/GoogleNews-vectors-negative300.bin.gz\")\n",
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('preTrained/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "\n",
    "print('모델의 크기(shape) :',word2vec_model.vectors.shape) # 모델의 크기 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7ec523",
   "metadata": {},
   "source": [
    "모든 값이 0으로 채워진 임베딩 행렬을 만들어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71558162",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 행렬의 크기(shape) : (16, 300)\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "print('임베딩 행렬의 크기(shape) :',np.shape(embedding_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d62780",
   "metadata": {},
   "source": [
    "word2vec_model에서 특정 단어를 입력하면 해당 단어의 임베딩 벡터를 리턴받을텐데, 만약 word2vec_model에 특정 단어의 임베딩 벡터가 없다면 None을 리턴하도록 하는 함수 get_vector()를 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6764f730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(word):\n",
    "    if word in word2vec_model:\n",
    "        return word2vec_model[word]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3596f17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, index in tokenizer.word_index.items():\n",
    "    # 단어와 맵핑되는 사전 훈련된 임베딩 벡터값\n",
    "    vector_value = get_vector(word)\n",
    "    if vector_value is not None:\n",
    "        embedding_matrix[index] = vector_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8ab73d",
   "metadata": {},
   "source": [
    "Embedding에 사전 훈련된 embedding_matrix를 입력으로 넣어주고 모델을 학습시켜보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcb98f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 - 0s - loss: 0.6977 - acc: 0.4286\n",
      "Epoch 2/100\n",
      "1/1 - 0s - loss: 0.6791 - acc: 0.5714\n",
      "Epoch 3/100\n",
      "1/1 - 0s - loss: 0.6611 - acc: 0.7143\n",
      "Epoch 4/100\n",
      "1/1 - 0s - loss: 0.6436 - acc: 0.7143\n",
      "Epoch 5/100\n",
      "1/1 - 0s - loss: 0.6266 - acc: 1.0000\n",
      "Epoch 6/100\n",
      "1/1 - 0s - loss: 0.6102 - acc: 1.0000\n",
      "Epoch 7/100\n",
      "1/1 - 0s - loss: 0.5943 - acc: 1.0000\n",
      "Epoch 8/100\n",
      "1/1 - 0s - loss: 0.5790 - acc: 1.0000\n",
      "Epoch 9/100\n",
      "1/1 - 0s - loss: 0.5641 - acc: 1.0000\n",
      "Epoch 10/100\n",
      "1/1 - 0s - loss: 0.5498 - acc: 1.0000\n",
      "Epoch 11/100\n",
      "1/1 - 0s - loss: 0.5359 - acc: 1.0000\n",
      "Epoch 12/100\n",
      "1/1 - 0s - loss: 0.5226 - acc: 1.0000\n",
      "Epoch 13/100\n",
      "1/1 - 0s - loss: 0.5096 - acc: 1.0000\n",
      "Epoch 14/100\n",
      "1/1 - 0s - loss: 0.4971 - acc: 1.0000\n",
      "Epoch 15/100\n",
      "1/1 - 0s - loss: 0.4850 - acc: 1.0000\n",
      "Epoch 16/100\n",
      "1/1 - 0s - loss: 0.4734 - acc: 1.0000\n",
      "Epoch 17/100\n",
      "1/1 - 0s - loss: 0.4621 - acc: 1.0000\n",
      "Epoch 18/100\n",
      "1/1 - 0s - loss: 0.4511 - acc: 1.0000\n",
      "Epoch 19/100\n",
      "1/1 - 0s - loss: 0.4406 - acc: 1.0000\n",
      "Epoch 20/100\n",
      "1/1 - 0s - loss: 0.4303 - acc: 1.0000\n",
      "Epoch 21/100\n",
      "1/1 - 0s - loss: 0.4204 - acc: 1.0000\n",
      "Epoch 22/100\n",
      "1/1 - 0s - loss: 0.4108 - acc: 1.0000\n",
      "Epoch 23/100\n",
      "1/1 - 0s - loss: 0.4015 - acc: 1.0000\n",
      "Epoch 24/100\n",
      "1/1 - 0s - loss: 0.3925 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "1/1 - 0s - loss: 0.3838 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "1/1 - 0s - loss: 0.3753 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 - 0s - loss: 0.3671 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 - 0s - loss: 0.3592 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 - 0s - loss: 0.3515 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 - 0s - loss: 0.3440 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 - 0s - loss: 0.3367 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 - 0s - loss: 0.3297 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 - 0s - loss: 0.3228 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 - 0s - loss: 0.3162 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 - 0s - loss: 0.3097 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 - 0s - loss: 0.3035 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 - 0s - loss: 0.2974 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 - 0s - loss: 0.2915 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 - 0s - loss: 0.2857 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 - 0s - loss: 0.2801 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 - 0s - loss: 0.2747 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 - 0s - loss: 0.2695 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 - 0s - loss: 0.2643 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 - 0s - loss: 0.2593 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 - 0s - loss: 0.2545 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 - 0s - loss: 0.2498 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 - 0s - loss: 0.2452 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 - 0s - loss: 0.2408 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 - 0s - loss: 0.2364 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 - 0s - loss: 0.2322 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 - 0s - loss: 0.2281 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 - 0s - loss: 0.2241 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 - 0s - loss: 0.2202 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 - 0s - loss: 0.2164 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 - 0s - loss: 0.2127 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 - 0s - loss: 0.2091 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 - 0s - loss: 0.2056 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 - 0s - loss: 0.2022 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 - 0s - loss: 0.1988 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 - 0s - loss: 0.1956 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 - 0s - loss: 0.1924 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 - 0s - loss: 0.1893 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 - 0s - loss: 0.1863 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 - 0s - loss: 0.1834 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 - 0s - loss: 0.1805 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 - 0s - loss: 0.1777 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 - 0s - loss: 0.1749 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 - 0s - loss: 0.1723 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 - 0s - loss: 0.1697 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 - 0s - loss: 0.1671 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 - 0s - loss: 0.1646 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 - 0s - loss: 0.1622 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 - 0s - loss: 0.1598 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 - 0s - loss: 0.1575 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 - 0s - loss: 0.1552 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 - 0s - loss: 0.1530 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 - 0s - loss: 0.1508 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 - 0s - loss: 0.1487 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 - 0s - loss: 0.1466 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 - 0s - loss: 0.1446 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 - 0s - loss: 0.1426 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 - 0s - loss: 0.1407 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 - 0s - loss: 0.1388 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 - 0s - loss: 0.1369 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 - 0s - loss: 0.1351 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 - 0s - loss: 0.1333 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 - 0s - loss: 0.1315 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 - 0s - loss: 0.1298 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 - 0s - loss: 0.1281 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 - 0s - loss: 0.1265 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 - 0s - loss: 0.1249 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 - 0s - loss: 0.1233 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 - 0s - loss: 0.1218 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 - 0s - loss: 0.1202 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 - 0s - loss: 0.1187 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 - 0s - loss: 0.1173 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 - 0s - loss: 0.1159 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 - 0s - loss: 0.1145 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 - 0s - loss: 0.1131 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 - 0s - loss: 0.1117 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22df5a63e48>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten, Input\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(Input(shape=(max_len,), dtype='int32'))\n",
    "e = Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=max_len, trainable=False)\n",
    "model.add(e)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.fit(X_train, y_train, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a938c07c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
