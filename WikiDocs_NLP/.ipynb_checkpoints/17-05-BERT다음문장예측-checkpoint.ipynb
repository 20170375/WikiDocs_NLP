{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f3d6068",
   "metadata": {},
   "source": [
    "# 17. BERT(Bidirectional Encoder Representations from Transformers)\n",
    "\n",
    "## 05) 구글 BERT의 다음 문장 예측(Next Sentence Prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa02454",
   "metadata": {},
   "source": [
    "```\n",
    "!pip install transformers\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb5069e",
   "metadata": {},
   "source": [
    "### 1. 다음 문장 예측 모델과 토크나이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1f3c246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFBertForNextSentencePrediction\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "473b1cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a77b25f0a6746b2a006925841e78d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/511M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForNextSentencePrediction.\n",
      "\n",
      "All the layers of TFBertForNextSentencePrediction were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForNextSentencePrediction for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d568a4",
   "metadata": {},
   "source": [
    "### 2. BERT의 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fa787c",
   "metadata": {},
   "source": [
    "다음 문장 예측을 위해 문맥 상으로 실제로 이어지는 두 개의 문장을 준비합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c6b3b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced.\"\n",
    "next_sentence = \"pizza is eaten with the use of a knife and fork. In casual settings, however, it is cut into wedges to be eaten while held in the hand.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff76925",
   "metadata": {},
   "source": [
    "앞서 준비한 bert-base-uncased의 토크나이저를 사용하여 두 개의 문장을 정수 인코딩해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09a836e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer(prompt, next_sentence, return_tensors='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dae70d8",
   "metadata": {},
   "source": [
    "토크나이저로 변환된 결과에서 input_ids를 통해 정수 인코딩 결과를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "390fb444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  101  1999  3304  1010 10733  2366  1999  5337 10906  1010  2107  2004\n",
      "   2012  1037  4825  1010  2003  3591  4895 14540  6610  2094  1012   102\n",
      "  10733  2003  8828  2007  1996  2224  1997  1037  5442  1998  9292  1012\n",
      "   1999 10017 10906  1010  2174  1010  2009  2003  3013  2046 17632  2015\n",
      "   2000  2022  8828  2096  2218  1999  1996  2192  1012   102]], shape=(1, 58), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(encoding['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c143f71f",
   "metadata": {},
   "source": [
    "여기서 주의할 점은 여기서 101과 102는 특별 토큰이라는 점입니다. 실제로 해당 토크나이저의 [CLS] 토큰과 [SEP] 토큰의 번호를 출력해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "997f4558",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] : 101\n",
      "[SEP] : 102\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.cls_token, ':', tokenizer.cls_token_id)\n",
    "print(tokenizer.sep_token, ':' , tokenizer.sep_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97187d7f",
   "metadata": {},
   "source": [
    "위의 정수 인코딩 결과를 다시 디코딩해보면 현재 입력의 구성을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bc9a02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] in italy, pizza served in formal settings, such as at a restaurant, is presented unsliced. [SEP] pizza is eaten with the use of a knife and fork. in casual settings, however, it is cut into wedges to be eaten while held in the hand. [SEP]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(encoding['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00fbfa5",
   "metadata": {},
   "source": [
    "토크나이저로 변환된 결과에서 token_type_ids를 통해서 문장을 구분하는 세그먼트 인코딩 결과를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "152ee047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]], shape=(1, 58), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(encoding['token_type_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7274e69",
   "metadata": {},
   "source": [
    "### 3. 다음 문장 예측하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21c6fb6",
   "metadata": {},
   "source": [
    "이제 TFBertForNextSentencePrediction를 통해서 다음 문장을 예측해봅시다. \n",
    "\n",
    "모델에 입력을 넣으면, 해당 모델은 소프트맥스 함수를 지나기 전의 값인 logits을 리턴합니다. 해당 값을 소프트맥스 함수를 통과시킨 후에 각 레이블에 대한 확률값을 출력해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2a4badb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[9.9999714e-01 2.8381912e-06]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "logits = model(encoding['input_ids'], token_type_ids=encoding['token_type_ids'])[0]\n",
    "softmax = tf.keras.layers.Softmax()\n",
    "probs = softmax(logits)\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1bcc6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 예측 레이블 : [0]\n"
     ]
    }
   ],
   "source": [
    "print('최종 예측 레이블 :', tf.math.argmax(probs, axis=-1).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0930bc65",
   "metadata": {},
   "source": [
    "최종 예측 레이블은 0입니다. 이는 BERT가 다음 문장 예측을 학습했을 당시에 실질적으로 이어지는 두 개의 문장의 레이블은 0. 이어지지 않는 두 개의 문장의 경우에는 레이블을 1로 두고서 이진 분류로 학습을 하였기 때문입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9992eb5",
   "metadata": {},
   "source": [
    "이번에는 이어지지 않는 두 개의 문장으로 테스트해봅시다. 전체적인 과정은 이전과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "feaaca3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 예측 레이블 : [1]\n"
     ]
    }
   ],
   "source": [
    "# 상관없는 두 개의 문장\n",
    "prompt = \"In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced.\"\n",
    "next_sentence = \"The sky is blue due to the shorter wavelength of blue light.\"\n",
    "encoding = tokenizer(prompt, next_sentence, return_tensors='tf')\n",
    "\n",
    "logits = model(encoding['input_ids'], token_type_ids=encoding['token_type_ids'])[0]\n",
    "\n",
    "softmax = tf.keras.layers.Softmax()\n",
    "probs = softmax(logits)\n",
    "print('최종 예측 레이블 :', tf.math.argmax(probs, axis=-1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f7aa14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
