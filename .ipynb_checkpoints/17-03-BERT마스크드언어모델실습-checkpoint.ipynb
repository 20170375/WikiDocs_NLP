{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80ba18bf",
   "metadata": {},
   "source": [
    "# 17. BERT(Bidirectional Encoder Representations from Transformers)\n",
    "\n",
    "## 03) 구글 BERT의 마스크드 언어 모델(Masked Language Model) 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b19b03",
   "metadata": {},
   "source": [
    "```\n",
    "!pip install transformers\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc05248b",
   "metadata": {},
   "source": [
    "### 1. 마스크드 언어 모델과 토크나이저"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97451016",
   "metadata": {},
   "source": [
    "BERT는 이미 누군가가 학습해둔 모델을 사용하는 것이므로 우리가 사용하는 모델과 토크나이저는 항상 맵핑 관계여야 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82438690",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertForMaskedLM\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c0438a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at bert-large-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForMaskedLM.from_pretrained('bert-large-uncased')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b5f2e9",
   "metadata": {},
   "source": [
    "### 2. BERT의 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8e8f902",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer('Soccer is a really fun [MASK].', return_tensors='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abbcf1f",
   "metadata": {},
   "source": [
    "토크나이저로 변환된 결과에서 input_ids를 통해 정수 인코딩 결과를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cb827f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[ 101 4715 2003 1037 2428 4569  103 1012  102]], shape=(1, 9), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976ef9a3",
   "metadata": {},
   "source": [
    "토크나이저로 변환된 결과에서 token_type_ids를 통해서 문장을 구분하는 세그먼트 인코딩 결과를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dab7a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0 0 0 0 0 0 0 0 0]], shape=(1, 9), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(inputs['token_type_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4390b153",
   "metadata": {},
   "source": [
    "토크나이저로 변환된 결과에서 attention_mask를 통해서 실제 단어와 패딩 토큰을 구분하는 용도인 어텐션 마스크를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47b510c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1 1 1 1 1 1 1 1 1]], shape=(1, 9), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(inputs['attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e52d2e",
   "metadata": {},
   "source": [
    "### 3. [MASK] 토큰 예측하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994d0cc5",
   "metadata": {},
   "source": [
    "FillMaskPipeline은 모델과 토크나이저를 지정하면 손쉽게 마스크드 언어 모델의 예측 결과를 정리해서 보여줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e279d750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import FillMaskPipeline\n",
    "pip = FillMaskPipeline(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "124c3f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.7621113657951355,\n",
       "  'token': 4368,\n",
       "  'token_str': 'sport',\n",
       "  'sequence': 'soccer is a really fun sport.'},\n",
       " {'score': 0.20342038571834564,\n",
       "  'token': 2208,\n",
       "  'token_str': 'game',\n",
       "  'sequence': 'soccer is a really fun game.'},\n",
       " {'score': 0.012208564206957817,\n",
       "  'token': 2518,\n",
       "  'token_str': 'thing',\n",
       "  'sequence': 'soccer is a really fun thing.'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pip('Soccer is a really fun [MASK].')[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "551a7d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.25628891587257385,\n",
       "  'token': 2265,\n",
       "  'token_str': 'show',\n",
       "  'sequence': 'the avengers is a really fun show.'},\n",
       " {'score': 0.17284151911735535,\n",
       "  'token': 3185,\n",
       "  'token_str': 'movie',\n",
       "  'sequence': 'the avengers is a really fun movie.'},\n",
       " {'score': 0.11107734590768814,\n",
       "  'token': 2466,\n",
       "  'token_str': 'story',\n",
       "  'sequence': 'the avengers is a really fun story.'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pip('The Avengers is a really fun [MASK].')[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c955a486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.35730674862861633,\n",
       "  'token': 2147,\n",
       "  'token_str': 'work',\n",
       "  'sequence': 'i went to work this morning.'},\n",
       " {'score': 0.23304493725299835,\n",
       "  'token': 2793,\n",
       "  'token_str': 'bed',\n",
       "  'sequence': 'i went to bed this morning.'},\n",
       " {'score': 0.12845060229301453,\n",
       "  'token': 2082,\n",
       "  'token_str': 'school',\n",
       "  'sequence': 'i went to school this morning.'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pip('I went to [MASK] this morning.')[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd678cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
