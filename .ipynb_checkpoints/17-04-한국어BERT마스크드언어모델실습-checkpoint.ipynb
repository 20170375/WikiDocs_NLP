{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "932d871e",
   "metadata": {},
   "source": [
    "# 17. BERT(Bidirectional Encoder Representations from Transformers)\n",
    "\n",
    "## 04) 한국어 BERT의 마스크드 언어 모델(Masked Language Model) 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02aa64a8",
   "metadata": {},
   "source": [
    "```\n",
    "!pip install transformers\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97cece3",
   "metadata": {},
   "source": [
    "### 1. 마스크드 언어 모델과 토크나이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68a26d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertForMaskedLM\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b751ada",
   "metadata": {},
   "source": [
    "from_pt=True는 해당 모델이 기존에는 텐서플로우가 아니라 파이토치로 학습된 모델이었지만 이를 텐서플로우에서 사용하겠다라는 의미입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04f8063c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f734dce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForMaskedLM: ['cls.predictions.decoder.bias', 'bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForMaskedLM from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForMaskedLM from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertForMaskedLM were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f6fee6a072546ed909356008c3c58e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/289 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81b8d2e9a022411bbf9fcc8594435182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/243k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc63a506527a45f0b492c8b40be6fc91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/483k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b2a5d168be454e84eb0dd581183598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = TFBertForMaskedLM.from_pretrained('klue/bert-base', from_pt=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4e18ab",
   "metadata": {},
   "source": [
    "### 2. BERT의 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4edbf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer('축구는 정말 재미있는 [MASK]다.', return_tensors='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe5e78b",
   "metadata": {},
   "source": [
    "토크나이저로 변환된 결과에서 input_ids를 통해 정수 인코딩 결과를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a332eac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[   2 4713 2259 3944 6001 2259    4  809   18    3]], shape=(1, 10), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e99e25",
   "metadata": {},
   "source": [
    "토크나이저로 변환된 결과에서 token_type_ids를 통해서 문장을 구분하는 세그먼트 인코딩 결과를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "526b818b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0 0 0 0 0 0 0 0 0 0]], shape=(1, 10), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(inputs['token_type_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7f7693",
   "metadata": {},
   "source": [
    "토크나이저로 변환된 결과에서 attention_mask를 통해서 실제 단어와 패딩 토큰을 구분하는 용도인 어텐션 마스크를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af8d547b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1 1 1 1 1 1 1 1 1 1]], shape=(1, 10), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(inputs['attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb3d575",
   "metadata": {},
   "source": [
    "### 3. [MASK] 토큰 예측하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fb4b9c",
   "metadata": {},
   "source": [
    "FillMaskPipeline은 모델과 토크나이저를 지정하면 손쉽게 마스크드 언어 모델의 예측 결과를 정리해서 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2f36daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import FillMaskPipeline\n",
    "pip = FillMaskPipeline(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b6f9a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.8963505029678345,\n",
       "  'token': 4559,\n",
       "  'token_str': '스포츠',\n",
       "  'sequence': '축구는 정말 재미있는 스포츠 다.'},\n",
       " {'score': 0.02595767006278038,\n",
       "  'token': 568,\n",
       "  'token_str': '거',\n",
       "  'sequence': '축구는 정말 재미있는 거 다.'},\n",
       " {'score': 0.0100339874625206,\n",
       "  'token': 3682,\n",
       "  'token_str': '경기',\n",
       "  'sequence': '축구는 정말 재미있는 경기 다.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pip('축구는 정말 재미있는 [MASK]다.')[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abf9ec75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.8382407426834106,\n",
       "  'token': 3771,\n",
       "  'token_str': '영화',\n",
       "  'sequence': '어벤져스는 정말 재미있는 영화 다.'},\n",
       " {'score': 0.02827557548880577,\n",
       "  'token': 568,\n",
       "  'token_str': '거',\n",
       "  'sequence': '어벤져스는 정말 재미있는 거 다.'},\n",
       " {'score': 0.017189398407936096,\n",
       "  'token': 4665,\n",
       "  'token_str': '드라마',\n",
       "  'sequence': '어벤져스는 정말 재미있는 드라마 다.'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pip('어벤져스는 정말 재미있는 [MASK]다.')[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba803000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.08012548089027405,\n",
       "  'token': 3769,\n",
       "  'token_str': '회사',\n",
       "  'sequence': '나는 오늘 아침에 회사 에 출근을 했다.'},\n",
       " {'score': 0.061240360140800476,\n",
       "  'token': 1,\n",
       "  'token_str': '[UNK]',\n",
       "  'sequence': '나는 오늘 아침에 에 출근을 했다.'},\n",
       " {'score': 0.01748662441968918,\n",
       "  'token': 4345,\n",
       "  'token_str': '공장',\n",
       "  'sequence': '나는 오늘 아침에 공장 에 출근을 했다.'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pip('나는 오늘 아침에 [MASK]에 출근을 했다.')[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f266c2cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
